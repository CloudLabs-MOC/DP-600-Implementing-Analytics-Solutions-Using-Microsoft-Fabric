# Module 05.2: Load data into a Microsoft Fabric data warehouse

## Lab scenario
In Microsoft Fabric, a data warehouse provides a relational database for large-scale analytics. Unlike the default read-only SQL endpoint for tables defined in a lakehouse, a data warehouse provides full SQL semantics; including the ability to insert, update, and delete data in the tables.

>**Note**: You need a Microsoft school or work account to complete this exercise. If you don’t have one, you can sign up for a trial of Microsoft Office 365 E3 or higher.

## Lab objectives
In this lab, you will perform:

- Create a lakehouse and upload files
- Create a table in the lakehouse
- Create a warehouse
- Create fact table, dimensions and view
- Load data to the warehouse
- Run analytical queries

## Estimated timing: 30 minutes

### Task 1: Create a lakehouse and upload files

Now that you have a workspace, it's time to switch to the *Data engineering* experience in the portal and create a data lakehouse for the data files you're going to analyze.

1. At the bottom left of the portal, select **Power BI** and select **Data Engineering** experience. In the **Synapse Data Engineering** home page, select **Lakehouse**.

    ![Screenshot of uploaded files in a lakehouse.](./Images/lab-5.2-2.png)

    ![Screenshot of uploaded files in a lakehouse.](./Images/lab-5.2-3.png)

1. Follow these instructions to create a new **Lakehouse**:

   - **Name:** Enter **Lakehouse<inject key="DeploymentID" enableCopy="false"/>**

   - Click on **Create**

1. Open a new tab and download the file for this exercise from **https://github.com/MicrosoftLearning/dp-data/blob/main/sales.csv**.

1. Return to the web browser tab containing your lakehouse, select **…** menu for the **Files** folder in the **Explorer** pane, select **Upload** and **Upload files**, then upload the **sales.csv** file from your lab VM to the lakehouse, and select **Upload**.

    ![Screenshot of uploaded files in a lakehouse.](./Images/lab-5.2-4.png)

1. After the files have been uploaded, select **Files**. Verify that the CSV file has been uploaded, as shown here:

    ![Screenshot of uploaded files in a lakehouse.](./Images/salesfileupload.png)

### Task 2: Create a table in the lakehouse

1. Select **…** menu for the **sales.csv** file in the **Explorer** pane, select **Load to tables**, and then **New table**.

    ![Screenshot of uploaded files in a lakehouse.](./Images/lab-5.2-6.png)

1. Provide the following information in the **Load file to new table** dialog. Select **Load**.

    - **New table name**: staging_sales
    - **Use header for columns names**: Selected
    - **Separator**: **, (comma)**

    ![Screenshot of uploaded files in a lakehouse.](./Images/lab-5.2-7.png)

### Task 3: Create a warehouse

1. At the bottom left of the Data Engineering portal, select the **Data Engineering** icon and switch to the **Data Warehouse** experience.

1. In the **Synapse Data Warehouse** home page, create a new **Warehouse** with a name **Warehouse<inject key="DeploymentID" enableCopy="false"/>**.

    >**Note:** After a minute or so, a new warehouse will be created:

    ![Screenshot of uploaded files in a lakehouse.](./Images/warehouse1.png)

### Task 4: Create fact table, dimensions and view

Let’s create the fact tables and dimensions for the Sales data. You’ll also create a view pointing to a lakehouse, this simplifies the code in the stored procedure we’ll use to load.

1. In the warehouse **Explorer**, select **New SQL query**, then copy and run the following query.

    ![Screenshot of uploaded files in a lakehouse.](./Images/lab-5.2-9.png)

    ```Sql
    CREATE SCHEMA [Sales]
    GO
            
    IF NOT EXISTS (SELECT * FROM sys.tables WHERE name='Fact_Sales' AND SCHEMA_NAME(schema_id)='Sales')
        CREATE TABLE Sales.Fact_Sales (
            CustomerID VARCHAR(255) NOT NULL,
            ItemID VARCHAR(255) NOT NULL,
            SalesOrderNumber VARCHAR(30),
            SalesOrderLineNumber INT,
            OrderDate DATE,
            Quantity INT,
            TaxAmount FLOAT,
            UnitPrice FLOAT
        );
        
    IF NOT EXISTS (SELECT * FROM sys.tables WHERE name='Dim_Customer' AND SCHEMA_NAME(schema_id)='Sales')
        CREATE TABLE Sales.Dim_Customer (
            CustomerID VARCHAR(255) NOT NULL,
            CustomerName VARCHAR(255) NOT NULL,
            EmailAddress VARCHAR(255) NOT NULL
        );
            
    ALTER TABLE Sales.Dim_Customer add CONSTRAINT PK_Dim_Customer PRIMARY KEY NONCLUSTERED (CustomerID) NOT ENFORCED
    GO
        
    IF NOT EXISTS (SELECT * FROM sys.tables WHERE name='Dim_Item' AND SCHEMA_NAME(schema_id)='Sales')
        CREATE TABLE Sales.Dim_Item (
            ItemID VARCHAR(255) NOT NULL,
            ItemName VARCHAR(255) NOT NULL
        );
            
    ALTER TABLE Sales.Dim_Item add CONSTRAINT PK_Dim_Item PRIMARY KEY NONCLUSTERED (ItemID) NOT ENFORCED
    GO
    ```
    >**Important:** In a data warehouse, foreign key constraints are not always necessary at the table level. While foreign key constraints can help ensure data integrity, they can also add overhead to the ETL (Extract, Transform, Load) process and slow down data loading. The decision to use foreign key constraints in a data warehouse should be based on a careful consideration of the trade-offs between data integrity and performance.

1. In the **Explorer**, navigate to **Schemas » Sales » Tables**. Note the **Fact_Sales, Dim_Customer**, and **Dim_Item** tables you just created.

    >**Note:** If tables are not present select **…** for Tables and choose refresh.

1. Open a new **New SQL query** editor, then copy and run the following query.

    ```Sql
    CREATE VIEW Sales.Staging_Sales
    AS
    SELECT * FROM [<your lakehouse name>].[dbo].[staging_sales];
    ```

    >**Note:** Update the **your lakehouse name** with the **Lakehouse<inject key="DeploymentID" enableCopy="false"/>**.

1. In the **Explorer**, navigate to **Schemas » Sales » Views**. Note the **Staging_Sales** view you created.

    ![Screenshot of uploaded files in a lakehouse.](./Images/stagingview.png)

### Task 5: Load data to the warehouse

Now that the fact and dimensions tables are created, let’s create a stored procedure to load the data from our lakehouse into the warehouse. Because of the automatic SQL endpoint created when we create the lakehouse, you can directly access the data in your lakehouse from the warehouse using T-SQL and cross-database queries.

For the sake of simplicity in this case study, you’ll use the customer's name and item name as the primary keys.

1. Create a new **New SQL query** editor, then copy and run the following query.

    ```Sql
    CREATE OR ALTER PROCEDURE Sales.LoadDataFromStaging (@OrderYear INT)
    AS
    BEGIN
        -- Load data into the Customer dimension table
        INSERT INTO Sales.Dim_Customer (CustomerID, CustomerName, EmailAddress)
        SELECT DISTINCT CustomerName, CustomerName, EmailAddress
        FROM [Sales].[Staging_Sales]
        WHERE YEAR(OrderDate) = @OrderYear
        AND NOT EXISTS (
            SELECT 1
            FROM Sales.Dim_Customer
            WHERE Sales.Dim_Customer.CustomerName = Sales.Staging_Sales.CustomerName
            AND Sales.Dim_Customer.EmailAddress = Sales.Staging_Sales.EmailAddress
        );
            
        -- Load data into the Item dimension table
        INSERT INTO Sales.Dim_Item (ItemID, ItemName)
        SELECT DISTINCT Item, Item
        FROM [Sales].[Staging_Sales]
        WHERE YEAR(OrderDate) = @OrderYear
        AND NOT EXISTS (
            SELECT 1
            FROM Sales.Dim_Item
            WHERE Sales.Dim_Item.ItemName = Sales.Staging_Sales.Item
        );
            
        -- Load data into the Sales fact table
        INSERT INTO Sales.Fact_Sales (CustomerID, ItemID, SalesOrderNumber, SalesOrderLineNumber, OrderDate, Quantity, TaxAmount, UnitPrice)
        SELECT CustomerName, Item, SalesOrderNumber, CAST(SalesOrderLineNumber AS INT), CAST(OrderDate AS DATE), CAST(Quantity AS INT), CAST(TaxAmount AS FLOAT), CAST(UnitPrice AS FLOAT)
        FROM [Sales].[Staging_Sales]
        WHERE YEAR(OrderDate) = @OrderYear;
    END
    ```

1. Create a new **New SQL query** editor, then copy and run the following query.

    ```Sql
    EXEC Sales.LoadDataFromStaging 2021
    ```

    >**Note:** In this case, it will only load data from the year 2021. However, you have the option to modify it to load data from previous years.

### Task 6: Run analytical queries

Let’s run some analytical queries to validate the data in the warehouse.

1. On the top menu, select **New SQL query**, then copy and run the following query.

    ```Sql
    SELECT c.CustomerName, SUM(s.UnitPrice * s.Quantity) AS TotalSales
    FROM Sales.Fact_Sales s
    JOIN Sales.Dim_Customer c
    ON s.CustomerID = c.CustomerID
    WHERE YEAR(s.OrderDate) = 2021
    GROUP BY c.CustomerName
    ORDER BY TotalSales DESC;
    ```

    >**Note:** This query shows the customers by total sales for the year of 2021. The customer with the highest total sales for the specified year is Jordan Turner, with total sales of 14686.69.

1. On the top menu, select **New SQL query** or reuse the same editor, then copy and run the following query.

    ```Sql
    SELECT i.ItemName, SUM(s.UnitPrice * s.Quantity) AS TotalSales
    FROM Sales.Fact_Sales s
    JOIN Sales.Dim_Item i
    ON s.ItemID = i.ItemID
    WHERE YEAR(s.OrderDate) = 2021
    GROUP BY i.ItemName
    ORDER BY TotalSales DESC;
    ```

    >**Note:** This query shows the top-seliing items by total sales for the year of 2021. These results suggest that the Mountain-200 bike model, in both black and silver colors, was the most popular item among customers in 2021.

1. On the top menu, select **New SQL query** or reuse the same editor, then copy and run the following query.

    ```Sql
    WITH CategorizedSales AS (
    SELECT
        CASE
            WHEN i.ItemName LIKE '%Helmet%' THEN 'Helmet'
            WHEN i.ItemName LIKE '%Bike%' THEN 'Bike'
            WHEN i.ItemName LIKE '%Gloves%' THEN 'Gloves'
            ELSE 'Other'
        END AS Category,
        c.CustomerName,
        s.UnitPrice * s.Quantity AS Sales
    FROM Sales.Fact_Sales s
    JOIN Sales.Dim_Customer c
    ON s.CustomerID = c.CustomerID
    JOIN Sales.Dim_Item i
    ON s.ItemID = i.ItemID
    WHERE YEAR(s.OrderDate) = 2021
    ),
    RankedSales AS (
        SELECT
            Category,
            CustomerName,
            SUM(Sales) AS TotalSales,
            ROW_NUMBER() OVER (PARTITION BY Category ORDER BY SUM(Sales) DESC) AS SalesRank
        FROM CategorizedSales
        WHERE Category IN ('Helmet', 'Bike', 'Gloves')
        GROUP BY Category, CustomerName
    )
    SELECT Category, CustomerName, TotalSales
    FROM RankedSales
    WHERE SalesRank = 1
    ORDER BY TotalSales DESC;
    ```

    >**Note:** The results of this query show the top customer for each of the categories: Bike, Helmet, and Gloves, based on their total sales. For example, Carson Butler is the top customer for the Bike category.

    ![Screenshot of uploaded files in a lakehouse.](./Images/output(5).png)

    > The category information was extracted from the ItemName column using string manipulation, as there is no separate category column in the dimension table. This approach assumes that the item names follow a consistent naming convention. If the item names do not follow a consistent naming convention, the results may not accurately reflect the true category of each item.

    > In this exercise, you have created a lakehouse and a data warehouse with multiple tables. You have ingested data and used cross-database queries to load data from the lakehouse to the warehouse. Additionally, you have used the query tool to perform analytical queries.

### Review
 In this lab, you have completed the following :
- Created a lakehouse and upload files
- Created a table in the lakehouse
- Created a warehouse
- Created fact table, dimensions and view
- Loaded data to the warehouse
- Ran analytical queries

## You have successfully completed the lab
